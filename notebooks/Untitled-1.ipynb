{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of v_load_summary_hourly Table\n",
    "\n",
    "This notebook analyzes the schema and contents of the v_load_summary_hourly table from AWS Glue Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load the parquet file\n",
    "file_path = '/local/home/admsia/parquet_analysis/load_summary.parquet'\n",
    "df = pd.read_parquet(file_path)\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Overview\n",
    "\n",
    "The table contains 116 columns with various data about vehicle routes, schedules, and logistics metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display table columns\n",
    "print(\"Column Names:\")\n",
    "columns = df.columns.tolist()\n",
    "for i, col in enumerate(columns):\n",
    "    print(f\"{i+1}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Show data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sample\n",
    "\n",
    "Here's a sample of the data to understand its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display a sample of the data\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Field Analysis\n",
    "\n",
    "Let's examine the distribution of key fields in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Program code distribution\n",
    "print(\"Program code distribution:\")\n",
    "print(df['program_code'].value_counts().head(10))\n",
    "\n",
    "# Shipment mode distribution\n",
    "print(\"\\nShipment mode distribution:\")\n",
    "print(df['shipment_mode'].value_counts())\n",
    "\n",
    "# Equipment type distribution\n",
    "print(\"\\nEquipment type distribution:\")\n",
    "print(df['equipment_type'].value_counts().head(10))\n",
    "\n",
    "# Vehicle execution status\n",
    "print(\"\\nVehicle execution status distribution:\")\n",
    "print(df['vehicle_execution_status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transit Time Analysis\n",
    "\n",
    "Analysis of scheduled vs. actual transit times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Transit time statistics\n",
    "print(\"Transit time statistics:\")\n",
    "df[['transit_hours_actual', 'scheduled_transit_hours']].describe()\n",
    "\n",
    "# Late arrival analysis\n",
    "print(\"\\nLate arrival statistics:\")\n",
    "print(f\"Origin arrival late hours - average: {df['origin_arrival_late_hrs'].mean()}\")\n",
    "print(f\"Origin arrival late hours - median: {df['origin_arrival_late_hrs'].median()}\")\n",
    "print(f\"Destination arrival late hours - average: {df['dest_arrival_late_hrs'].mean()}\")\n",
    "print(f\"Destination arrival late hours - median: {df['dest_arrival_late_hrs'].median()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Route Analysis\n",
    "\n",
    "Examining characteristics of the routes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Miles distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['miles'], bins=50)\n",
    "plt.title('Distribution of Route Miles')\n",
    "plt.xlabel('Miles')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Stop count distribution\n",
    "print(\"Stop count distribution:\")\n",
    "print(df['stop_count'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL-Style Schema Definition\n",
    "\n",
    "Below is an SQL representation of the schema with descriptions of each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Print the SQL schema definition\n",
    "sql_schema = \"\"\"\n",
    "CREATE TABLE v_load_summary_hourly (\n",
    "  vrid VARCHAR,                         -- Unique vehicle route ID\n",
    "  unused_region_id VARCHAR,             -- Unused region identifier\n",
    "  unused_report_day TIMESTAMP,          -- Unused report day timestamp\n",
    "  report_week VARCHAR,                  -- Week of the report (e.g., W27)\n",
    "  report_month VARCHAR,                 -- Month of the report (e.g., M07)\n",
    "  program_code VARCHAR,                 -- Purpose code (EMPTY, XFER, SCIB, AMZL, etc.)\n",
    "  carrier_manager VARCHAR,              -- Carrier manager\n",
    "  tp_id VARCHAR,                        -- Transport plan ID\n",
    "  tour_id VARCHAR,                      -- Tour identifier\n",
    "  scac VARCHAR,                         -- Standard Carrier Alpha Code\n",
    "  carrier_name VARCHAR,                 -- Name of the carrier\n",
    "  subcarrier VARCHAR,                   -- Subcarrier code\n",
    "  carrier_group VARCHAR,                -- Carrier group (e.g., ATS_BROKERAGE, ATS_DEDICATED)\n",
    "  lane VARCHAR,                         -- Origin to destination route (e.g., DCL4->CLE2)\n",
    "  stop_count INT,                       -- Number of stops\n",
    "  account_id VARCHAR,                   -- Business purpose identifier\n",
    "  shipment_mode VARCHAR,                -- Mode of shipment (TRUCKLOAD, INTERMODAL, LESS_THAN_TRUCKLOAD)\n",
    "  miles INT,                            -- Distance in miles\n",
    "  cpt TIMESTAMP,                        -- Critical pull time/commitment\n",
    "  adhoc_load VARCHAR,                   -- Whether the load is adhoc\n",
    "  equipment_type VARCHAR,               -- Type of equipment/vehicle\n",
    "  transit_operator_type VARCHAR,        -- Type of driver operation (e.g., SINGLE_DRIVER)\n",
    "  tr_id VARCHAR,                        -- Transport record ID\n",
    "  crid VARCHAR,                         -- Customer reference ID\n",
    "  canceled_load VARCHAR,                -- Whether load was canceled (TRUE/FALSE)\n",
    "  canceled_date TIMESTAMP,              -- Date and time of cancellation\n",
    "  cancelation_reason VARCHAR,           -- Reason for cancellation\n",
    "  origin VARCHAR,                       -- Origin facility code\n",
    "  origin_zip VARCHAR,                   -- Origin ZIP code\n",
    "  origin_city VARCHAR,                  -- Origin city\n",
    "  origin_state VARCHAR,                 -- Origin state\n",
    "  origin_country VARCHAR,               -- Origin country\n",
    "  origin_type VARCHAR,                  -- Type of origin facility\n",
    "  origin_local_timezone VARCHAR,        -- Local timezone of origin\n",
    "  final_destination VARCHAR,            -- Destination facility code\n",
    "  dest_zip VARCHAR,                     -- Destination ZIP code\n",
    "  dest_city VARCHAR,                    -- Destination city\n",
    "  dest_state VARCHAR,                   -- Destination state\n",
    "  dest_country VARCHAR,                 -- Destination country\n",
    "  destination_type VARCHAR,             -- Type of destination facility\n",
    "  dest_local_timezone VARCHAR,          -- Local timezone of destination\n",
    "  manifest_base DECIMAL,                -- Base manifest cost\n",
    "  manifest_fuel DECIMAL,                -- Fuel manifest cost\n",
    "  manifest_total DECIMAL,               -- Total manifest cost\n",
    "  total_invoice_amount DECIMAL,         -- Total invoice amount\n",
    "  total_paid_amount DECIMAL,            -- Total paid amount\n",
    "  total_accessorials DECIMAL,           -- Total accessorial charges\n",
    "  estimated_cost_accrual DECIMAL,       -- Estimated cost accrual\n",
    "  accrual_cost_source VARCHAR,          -- Source of accrual cost\n",
    "  tour_day_rate DECIMAL,                -- Day rate for tour\n",
    "  total_pkg_unit_count INT,             -- Total package/unit count\n",
    "  total_cube DECIMAL,                   -- Total cubic volume\n",
    "  pallet_count INT,                     -- Count of pallets\n",
    "  gaylord_count INT,                    -- Count of gaylord containers\n",
    "  cube_target_cubic_ft DECIMAL,         -- Target cubic feet\n",
    "  global_dea_pkgs VARCHAR,              -- Global DEA packages\n",
    "  transit_hours_actual DECIMAL,         -- Actual transit hours\n",
    "  scheduled_transit_hours DECIMAL,      -- Scheduled transit hours\n",
    "  origin_scheduled_arrival TIMESTAMP,   -- Scheduled arrival at origin\n",
    "  origin_calc_arrival TIMESTAMP,        -- Calculated/actual arrival at origin\n",
    "  origin_calc_arrival_source VARCHAR,   -- Source of origin arrival calculation\n",
    "  origin_begin_loading_time TIMESTAMP,  -- Beginning of loading at origin\n",
    "  origin_finish_loading_time TIMESTAMP, -- End of loading at origin\n",
    "  origin_arrival_late_group VARCHAR,    -- Grouping for origin arrival lateness\n",
    "  origin_arrival_late_hrs DECIMAL,      -- Hours late at origin arrival (negative is early)\n",
    "  origin_responsible VARCHAR,           -- Responsible party at origin\n",
    "  origin_arrival_reason VARCHAR,        -- Reason for arrival timing at origin\n",
    "  origin_arrival_note VARCHAR,          -- Notes regarding origin arrival\n",
    "  origin_scheduled_depart TIMESTAMP,    -- Scheduled departure from origin\n",
    "  origin_calc_depart TIMESTAMP,         -- Calculated/actual departure from origin\n",
    "  origin_calc_depart_source VARCHAR,    -- Source of origin departure calculation\n",
    "  origin_departure_late_group VARCHAR,  -- Grouping for origin departure lateness\n",
    "  origin_depart_late_hrs DECIMAL,       -- Hours late at origin departure (negative is early)\n",
    "  origin_fc_delay_hours DECIMAL,        -- Hours of delay at origin facility\n",
    "  dest_scheduled_arrival TIMESTAMP,     -- Scheduled arrival at destination\n",
    "  dest_calc_arrival TIMESTAMP,          -- Calculated/actual arrival at destination\n",
    "  dest_calc_arrival_source VARCHAR,     -- Source of destination arrival calculation\n",
    "  dest_begin_unloading_time TIMESTAMP,  -- Beginning of unloading at destination\n",
    "  dest_finish_unloading_time TIMESTAMP, -- End of unloading at destination\n",
    "  late_to_destination_per_calc VARCHAR, -- Whether late to destination per calculation\n",
    "  dest_arrival_late_group VARCHAR,      -- Grouping for destination arrival lateness\n",
    "  dest_arrival_late_hrs DECIMAL,        -- Hours late at destination arrival (negative is early)\n",
    "  dest_responsible VARCHAR,             -- Responsible party at destination\n",
    "  dest_arrival_note VARCHAR,            -- Notes regarding destination arrival\n",
    "  dest_arrival_reason VARCHAR,          -- Reason for arrival timing at destination\n",
    "  trailer_id VARCHAR,                   -- Trailer identifier\n",
    "  bobtail_trailer_id VARCHAR,           -- Bobtail trailer identifier\n",
    "  driver_id VARCHAR,                    -- Driver identifier\n",
    "  driver_id_2 VARCHAR,                  -- Secondary driver identifier\n",
    "  arc_type VARCHAR,                     -- ARC type\n",
    "  wims_load VARCHAR,                    -- Whether it's a WIMS load\n",
    "  enrichment_flag VARCHAR,              -- Enrichment flag\n",
    "  tem_owned VARCHAR,                    -- TEM owned indicator\n",
    "  run_structure_id VARCHAR,             -- Run structure identifier\n",
    "  oneday_core_pkgs VARCHAR,             -- One-day core packages\n",
    "  trailer_ready_time TIMESTAMP,         -- Time trailer is ready\n",
    "  rate_type VARCHAR,                    -- Rate type (PER_LOAD, PER_TRIP)\n",
    "  origin_load_type VARCHAR,             -- Type of loading at origin\n",
    "  dest_unload_type VARCHAR,             -- Type of unloading at destination\n",
    "  drop_trailer_time TIMESTAMP,          -- Time of trailer drop\n",
    "  resource_block_id VARCHAR,            -- Resource block identifier\n",
    "  operator_id VARCHAR,                  -- Operator identifier\n",
    "  container_program VARCHAR,            -- Container program\n",
    "  containerized_pkgs DECIMAL,           -- Containerized packages\n",
    "  gl_account VARCHAR,                   -- General ledger account\n",
    "  vr_create_date TIMESTAMP,             -- Vehicle route creation date\n",
    "  rlb_load VARCHAR,                     -- RLB load indicator\n",
    "  plan_type VARCHAR,                    -- Plan type\n",
    "  movement_type VARCHAR,                -- Movement type\n",
    "  power_id VARCHAR,                     -- Power unit identifier\n",
    "  tem_rsp_region VARCHAR,               -- TEM responsible region\n",
    "  is_customer_facing VARCHAR,           -- Customer facing indicator\n",
    "  vehicle_execution_status VARCHAR,     -- Execution status (COMPLETED, CANCELLED, etc.)\n",
    "  facility_sequence VARCHAR,            -- Facility sequence\n",
    "  dest_planned_arrival TIMESTAMP,       -- Planned arrival at destination\n",
    "  region_id VARCHAR                     -- Region identifier\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(sql_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Completeness\n",
    "\n",
    "Checking for missing values in key columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate missing values percentage\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "\n",
    "# Create a dataframe with the results\n",
    "missing_info = pd.DataFrame({\n",
    "    'Missing Values': missing_data,\n",
    "    'Missing Percent': missing_percent\n",
    "})\n",
    "\n",
    "# Sort by missing percent\n",
    "missing_info = missing_info[missing_info['Missing Values'] > 0].sort_values('Missing Percent', ascending=False)\n",
    "missing_info.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}